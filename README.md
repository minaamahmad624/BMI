This project explores the use of facial landmark-based features for predicting height and weight of a human body. A dataset of facial images was annotated using the shape_predictor_68_face_landmarks model to extract key facial dimensions such as eye distance, nose-to-chin distance, and jaw width. Height and weight were manually added to the dataset as target variables. Machine learning models, including Linear Regression, Support Vector Machines, and Random Forest were trained on the extracted features to predict the target variables. The models were evaluated using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (RÂ²). Results highlight the potential of facial dimensions to estimate Height and Weight opening the doors for further advancements in health monitoring applications. Future work involves extending the dataset and incorporating deep learning for improved accuracy.

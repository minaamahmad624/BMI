{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected in image56.jpg\n",
      "No face detected in image57.jpg\n",
      "No face detected in image64.jpg\n",
      "No face detected in image84.jpg\n",
      "No face detected in image89.jpg\n",
      "No face detected in image90.jpg\n",
      "No face detected in image92.jpg\n",
      "Feature extraction complete. Data saved to features_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "input_folder = \"./images\"  # Replace with the path to your folder containing images\n",
    "output_csv = \"features_dataset.csv\"\n",
    "\n",
    "# Load pre-trained models\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Helper function to extract distances between landmarks\n",
    "def extract_features(shape):\n",
    "    # Key landmarks\n",
    "    left_eye = shape[36]\n",
    "    right_eye = shape[45]\n",
    "    nose_tip = shape[33]\n",
    "    left_mouth = shape[48]\n",
    "    right_mouth = shape[54]\n",
    "    chin = shape[8]\n",
    "    left_jaw = shape[0]\n",
    "    right_jaw = shape[16]\n",
    "\n",
    "    # Feature calculations (distances in pixel units)\n",
    "    features = {\n",
    "        \"eye_distance\": ((right_eye[0] - left_eye[0]) ** 2 + (right_eye[1] - left_eye[1]) ** 2) ** 0.5,\n",
    "        \"nose_to_chin\": ((chin[0] - nose_tip[0]) ** 2 + (chin[1] - nose_tip[1]) ** 2) ** 0.5,\n",
    "        \"mouth_width\": ((right_mouth[0] - left_mouth[0]) ** 2 + (right_mouth[1] - left_mouth[1]) ** 2) ** 0.5,\n",
    "        \"jaw_width\": ((right_jaw[0] - left_jaw[0]) ** 2 + (right_jaw[1] - left_jaw[1]) ** 2) ** 0.5,\n",
    "        \"nose_to_eye\": ((nose_tip[0] - left_eye[0]) ** 2 + (nose_tip[1] - left_eye[1]) ** 2) ** 0.5,\n",
    "    }\n",
    "\n",
    "    return features\n",
    "\n",
    "# Iterate over images and process\n",
    "features_list = []\n",
    "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(input_folder, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = detector(gray)\n",
    "    if len(faces) > 0:\n",
    "        # Assume the first detected face\n",
    "        face = faces[0]\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Convert landmarks to a list of tuples\n",
    "        shape = [(landmarks.part(i).x, landmarks.part(i).y) for i in range(68)]\n",
    "\n",
    "        # Extract features\n",
    "        features = extract_features(shape)\n",
    "        features[\"image_name\"] = image_file\n",
    "        features_list.append(features)\n",
    "    else:\n",
    "        print(f\"No face detected in {image_file}\")\n",
    "\n",
    "# Save features to CSV\n",
    "df = pd.DataFrame(features_list)\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Feature extraction complete. Data saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
